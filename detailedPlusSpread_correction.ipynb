{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm6iASDYdo0AF6jfvEll5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayTaori/merged_et_close/blob/main/detailedPlusSpread_correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wnax-G5D274s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import time\n",
        "import calendar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_open_merged = pd.read_csv('/content/crypto_et_open_merged.csv')\n",
        "df_close_merged = pd.read_csv('/content/crypto_et_closed_merged.csv')"
      ],
      "metadata": {
        "id": "PNwdP03q4nik"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_open_merged['Date'] = pd.to_datetime(df_open_merged['Date'],dayfirst=True)\n",
        "df_open_merged['Open Date'] = pd.to_datetime(df_open_merged['Open Date'],dayfirst=True)\n",
        "df_close_merged['Date'] = pd.to_datetime(df_close_merged['Date'],dayfirst=True)\n",
        "df_close_merged['Close Date'] = pd.to_datetime(df_close_merged['Close Date'],dayfirst=True)"
      ],
      "metadata": {
        "id": "0vcb4wJL6hmu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_excel('/content/etoro-account-statement-1-1-2021-12-31-2021.xlsx',sheet_name=2)\n",
        "df = pd.read_excel('Assesment of taxes 2020_etoro.xlsx', sheet_name=0)\n",
        "df_new_2022 = pd.read_excel('/content/etoro-account-statement-1-1-2022-12-31-2022_Pandas.xlsx',sheet_name=2)\n",
        "df1 = df.drop(['Leverage',\n",
        "               'Stop lose rate',\n",
        "               'Take profit rate',\n",
        "               'Stop lose rate',\n",
        "               'Rollover Fees and Dividends',\n",
        "               'Copied From',\n",
        "               'Type'\n",
        "               ], axis=1)\n",
        "df_new_1 = df_new.drop(['Leverage',\n",
        "               'Stop lose rate',\n",
        "               'Take profit rate',\n",
        "               'Stop lose rate',\n",
        "               'Rollover Fees and Dividends',\n",
        "               'Copied From',\n",
        "               'Type', 'Notes', 'ISIN'\n",
        "               ], axis=1)\n",
        "df_new_2022_1 = df_new_2022.drop(['Leverage',\n",
        "               'Stop lose rate',\n",
        "               'Take profit rate',\n",
        "               'Stop lose rate',\n",
        "               'Rollover Fees and Dividends',\n",
        "               'Copied From',\n",
        "               'Type', 'Notes', 'ISIN'\n",
        "               ], axis=1)\n",
        "df_20_open = df1[['Position ID', \n",
        "                'Action', 'Amount', 'Units', 'Open Date', 'Open Rate']]\n",
        "df_21_open = df_new_1[['Position ID', \n",
        "                'Action', 'Amount', 'Units', 'Open Date', 'Open Rate']]\n",
        "df_22_open = df_new_2022_1[['Position ID', \n",
        "                'Action', 'Amount', 'Units', 'Open Date', 'Open Rate']]\n",
        "df_20_close = df1[['Position ID', \n",
        "                'Action', 'Units', 'Close Date', \n",
        "                'Close Rate','Spread', 'Profit']]\n",
        "df_21_close = df_new_1[['Position ID', \n",
        "                'Action', 'Units', 'Close Date', \n",
        "                'Close Rate','Spread', 'Profit']]\n",
        "df_22_close = df_new_2022_1[['Position ID', \n",
        "                'Action', 'Units', 'Close Date', \n",
        "                'Close Rate','Spread', 'Profit']]              "
      ],
      "metadata": {
        "id": "IhvHvILi8llp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eur_all = pd.read_csv('/content/eur_usd_all_plus_weekends.csv')\n",
        "df_eur_all"
      ],
      "metadata": {
        "id": "VuopyslsC7Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eur_all['Date'] = pd.to_datetime(df_eur_all['Date'],dayfirst=True)"
      ],
      "metadata": {
        "id": "6-hBMPBIDubF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_20_open['Open Date'] = pd.to_datetime(df_20_open['Open Date'],dayfirst=True)\n",
        "df_21_open['Open Date'] = pd.to_datetime(df_21_open['Open Date'],dayfirst=True)\n",
        "df_22_open['Open Date'] = pd.to_datetime(df_22_open['Open Date'],dayfirst=True)\n",
        "df_20_close['Close Date'] = pd.to_datetime(df_20_close['Close Date'],dayfirst=True)\n",
        "df_21_close['Close Date'] = pd.to_datetime(df_21_close['Close Date'],dayfirst=True)\n",
        "df_22_close['Close Date'] = pd.to_datetime(df_22_close['Close Date'],dayfirst=True)"
      ],
      "metadata": {
        "id": "37oxVK4PD-Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datetime2date(date_time):\n",
        "  date = date_time.date()\n",
        "  return date"
      ],
      "metadata": {
        "id": "s-Rik6gqEUPu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_20_open['Date'] = df_20_open['Open Date']\n",
        "df_20_open['Date'] = pd.to_datetime(df_20_open['Date'],dayfirst=True)\n",
        "df_20_open['Date'] = df_20_open['Date'].map(datetime2date)\n",
        "df_21_open['Date'] = df_21_open['Open Date']\n",
        "df_21_open['Date'] = pd.to_datetime(df_21_open['Date'],dayfirst=True)\n",
        "df_21_open['Date'] = df_21_open['Date'].map(datetime2date)\n",
        "df_22_open['Date'] = df_22_open['Open Date']\n",
        "df_22_open['Date'] = pd.to_datetime(df_22_open['Date'],dayfirst=True)\n",
        "df_22_open['Date'] = df_22_open['Date'].map(datetime2date)\n",
        "df_20_close['Date'] = df_20_close['Close Date']\n",
        "df_20_close['Date'] = pd.to_datetime(df_20_close['Date'],dayfirst=True)\n",
        "df_20_close['Date'] = df_20_close['Date'].map(datetime2date)\n",
        "df_21_close['Date'] = df_21_close['Close Date']\n",
        "df_21_close['Date'] = pd.to_datetime(df_21_close['Date'],dayfirst=True)\n",
        "df_21_close['Date'] = df_21_close['Date'].map(datetime2date)\n",
        "df_22_close['Date'] = df_22_close['Close Date']\n",
        "df_22_close['Date'] = pd.to_datetime(df_22_close['Date'],dayfirst=True)\n",
        "df_22_close['Date'] = df_22_close['Date'].map(datetime2date)\n",
        "df_20_open['Date'] = pd.to_datetime(df_20_open['Date'],dayfirst=True)\n",
        "df_20_close['Date'] = pd.to_datetime(df_20_close['Date'],dayfirst=True)\n",
        "df_21_open['Date'] = pd.to_datetime(df_21_open['Date'],dayfirst=True)\n",
        "df_21_close['Date'] = pd.to_datetime(df_21_close['Date'],dayfirst=True)\n",
        "df_22_open['Date'] = pd.to_datetime(df_22_open['Date'],dayfirst=True)\n",
        "df_22_close['Date'] = pd.to_datetime(df_22_close['Date'],dayfirst=True)"
      ],
      "metadata": {
        "id": "sY5ewIw0EcQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_20_open"
      ],
      "metadata": {
        "id": "o-m6bTkFFMNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open = pd.concat([df_20_open,df_21_open,df_22_open])"
      ],
      "metadata": {
        "id": "FdGBOxD0FWal"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_20_close"
      ],
      "metadata": {
        "id": "7OpJCOq0Fn9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close = pd.concat([df_20_close,df_21_close,df_22_close])"
      ],
      "metadata": {
        "id": "UkxPR807F0na"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open.reset_index(inplace=True)\n",
        "df_et_open.drop('index',axis=1,inplace=True)\n",
        "df_et_close.reset_index(inplace=True)\n",
        "df_et_close.drop('index',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "x_cRjojDF7TG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_find_na = df_et_open # use the DataFrame for which you would like to find NANs\n",
        "columns_df_find_na = df_find_na.columns\n",
        "def find_null_values(column_name):\n",
        "  print('The number of null values in column {} are:'.format(column_name),len(np.where(df_find_na.isna()[column_name])[0]))\n",
        "  print('And their integer location is:', np.where(df_find_na.isna()[column_name])[0])\n",
        "null_values = [find_null_values(y) for y in columns_df_find_na]"
      ],
      "metadata": {
        "id": "GPf81UFaGDxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_find_na = df_et_close # use the DataFrame for which you would like to find NANs\n",
        "columns_df_find_na = df_find_na.columns\n",
        "def find_null_values(column_name):\n",
        "  print('The number of null values in column {} are:'.format(column_name),len(np.where(df_find_na.isna()[column_name])[0]))\n",
        "  print('And their integer location is:', np.where(df_find_na.isna()[column_name])[0])\n",
        "null_values = [find_null_values(y) for y in columns_df_find_na]"
      ],
      "metadata": {
        "id": "JMmKiuCkGhj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert2UnixTimestamp(date_time):\n",
        "  unix_timestamp = time.mktime(date_time.timetuple())\n",
        "  return unix_timestamp"
      ],
      "metadata": {
        "id": "XI048lRMEIEW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open['open_unix_timestamp'] = df_et_open['Open Date'].map(convert2UnixTimestamp)\n",
        "df_et_close['close_unix_timestamp'] = df_et_close['Close Date'].map(convert2UnixTimestamp)"
      ],
      "metadata": {
        "id": "qzkVzr3QHM6B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Warning!!! the euro to usd is not included in these files.\n",
        "Everything else is until here is included.\n",
        "df_et_open.to_csv('crypto_et_open_unixTstm.csv',index=False)\n",
        "df_et_close.to_csv('crypto_et_close_unixTstm.csv',index=False)\n",
        "'''"
      ],
      "metadata": {
        "id": "45R60_osHZ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close_eur1 = pd.merge(df_et_close, df_eur_all, on='Date')\n",
        "df_et_open_eur1 = pd.merge(df_et_open, df_eur_all, on='Date')"
      ],
      "metadata": {
        "id": "DqElrw3QH74d"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1.nunique()"
      ],
      "metadata": {
        "id": "VCGR-q9_IfHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close_eur1.nunique()"
      ],
      "metadata": {
        "id": "zSA5c4EdIjPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_find_na = df_et_open_eur1 # use the DataFrame for which you would like to find NANs\n",
        "columns_df_find_na = df_find_na.columns\n",
        "def find_null_values(column_name):\n",
        "  print('The number of null values in column {} are:'.format(column_name),len(np.where(df_find_na.isna()[column_name])[0]))\n",
        "  print('And their integer location is:', np.where(df_find_na.isna()[column_name])[0])\n",
        "null_values = [find_null_values(y) for y in columns_df_find_na]"
      ],
      "metadata": {
        "id": "s1DXesJzJCf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_find_na = df_et_close_eur1 # use the DataFrame for which you would like to find NANs\n",
        "columns_df_find_na = df_find_na.columns\n",
        "def find_null_values(column_name):\n",
        "  print('The number of null values in column {} are:'.format(column_name),len(np.where(df_find_na.isna()[column_name])[0]))\n",
        "  print('And their integer location is:', np.where(df_find_na.isna()[column_name])[0])\n",
        "null_values = [find_null_values(y) for y in columns_df_find_na]"
      ],
      "metadata": {
        "id": "V88qtN1EJMMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1['Amount_Eur'] = df_et_open_eur1['Amount']/df_et_open_eur1['Low']\n",
        "df_et_open_eur1['Open Rate_Eur'] = df_et_open_eur1['Open Rate']/df_et_open_eur1['Low']\n",
        "df_et_close_eur1['Close Rate_Eur'] = df_et_close_eur1['Close Rate']/df_et_close_eur1['High']\n",
        "df_et_close_eur1['Amount_close_Eur'] = df_et_close_eur1['Close Rate_Eur']*df_et_close_eur1['Units']\n",
        "df_et_close_eur1['Spread_Eur'] = df_et_close_eur1['Spread']/df_et_close_eur1['Low']"
      ],
      "metadata": {
        "id": "5WTi_SQrJga1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close_eur1.transpose()"
      ],
      "metadata": {
        "id": "Qnh1oLcYOG6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1.columns"
      ],
      "metadata": {
        "id": "dOCW0UgBtOHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1.rename(columns={'Position ID': 'Open Position ID',\n",
        "                                'Action':'Open Action', 'Amount':'Open Amount',\n",
        "                                'Units':'Open Units',\n",
        "                                'Open Date':'Open Datetime',\n",
        "                                'Date':'Open_Date', \n",
        "                                'Amount_Eur':'Open Amount_Eur',\n",
        "                                'open_unix_timestamp':'Open_unix_timestamp',\n",
        "                                'Open':'EurOpen_x', 'High':'EurHigh_x',\n",
        "                                'Low':'EurLow_x','Close':'EurClose_x',\n",
        "                                'Weekday':'EurWeekday_x'}\n",
        "                       ).transpose()"
      ],
      "metadata": {
        "id": "HTsoAeB1tH9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1.rename(columns={'Position ID': 'Open Position ID',\n",
        "                                'Action':'Open Action', 'Amount':'Open Amount',\n",
        "                                'Units':'Open Units',\n",
        "                                'Open Date':'Open Datetime',\n",
        "                                'Date':'Open_Date', \n",
        "                                'Amount_Eur':'Open Amount_Eur',\n",
        "                                'open_unix_timestamp':'Open_unix_timestamp',\n",
        "                                'Open':'EurOpen_x', 'High':'EurHigh_x',\n",
        "                                'Low':'EurLow_x','Close':'EurClose_x',\n",
        "                                'Weekday':'EurWeekday_x'},\n",
        "                       inplace=True)"
      ],
      "metadata": {
        "id": "IRPJA9-Kw0o0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close_eur1.columns"
      ],
      "metadata": {
        "id": "y9h-KU7xOzk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close_eur1.rename(columns={'Position ID': 'Close Position ID',\n",
        "                                 'Action':'Close Action', 'Units':'Close Units',\n",
        "                                 'Spread':'Close Spread',\n",
        "                                 'Close Date':'Close Datetime',\n",
        "                                 'Date':'Close_Date',\n",
        "                                 'Profit':'Close Profit USD',\n",
        "                                 'close_unix_timestamp':'Close_unix_timestamp',\n",
        "                                 'Open':'EurOpen_y', 'High':'EurHigh_y',\n",
        "                                 'Low':'EurLow_y',\n",
        "                                 'Close':'EurClose_y','Weekday':'EurWeekday_y'},\n",
        "                        inplace=True)"
      ],
      "metadata": {
        "id": "7HU1-Ze1PqIz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close_eur1"
      ],
      "metadata": {
        "id": "k2iDcRvbw-Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_open['open_unix_timestamp'] = pd.to_numeric(df_open['open_unix_timestamp'])\n",
        "#df_open['Open Datetime'] = pd.to_datetime(df_open['open_unix_timestamp'],dayfirst=True,unit='s')"
      ],
      "metadata": {
        "id": "i-5I928d0L2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1.sort_values(by='Open_unix_timestamp',inplace=True)"
      ],
      "metadata": {
        "id": "qeWWiZyg0Wh9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1.reset_index(inplace=True)\n",
        "df_et_open_eur1.drop('index', axis=1,inplace=True)\n",
        "df_et_open_eur1"
      ],
      "metadata": {
        "id": "Bg8tzbB82wyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_close_eur1.sort_values(by='Close_unix_timestamp',inplace=True)\n",
        "df_et_close_eur1.reset_index(inplace=True)\n",
        "df_et_close_eur1.drop('index', axis=1,inplace=True)\n",
        "df_et_close_eur1"
      ],
      "metadata": {
        "id": "4AB6RD-J1lIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_et_open_eur1.to_csv('et_open_alldata.csv',index=False)\n",
        "df_et_close_eur1.to_csv('et_close_alldata.csv',index=False)"
      ],
      "metadata": {
        "id": "Rta7qQRR3IXc"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}